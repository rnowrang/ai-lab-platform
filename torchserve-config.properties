# TorchServe Configuration
inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8081
metrics_address=http://0.0.0.0:8082

# Model store
model_store=/mnt/models

# Batch configuration
default_batch_size=1
max_batch_delay=100

# Workers configuration  
default_workers_per_model=1
max_workers=4

# Request configuration
max_request_size=100000000
max_response_size=100000000

# Metrics
enable_metrics_api=true
metrics_format=prometheus

# Logging
default_log_level=INFO

# CORS
cors_allowed_origin=*
cors_allowed_methods=GET,POST,PUT,DELETE
cors_allowed_headers=*

# GPU configuration
number_of_gpu=1

# Model URL whitelist
allowed_urls=file://,http://,https://

# Model configuration file
model_config_file=/mnt/models/models.json 